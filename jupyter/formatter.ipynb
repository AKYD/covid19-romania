{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install influxdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from influxdb import DataFrameClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'admin'\n",
    "password = 'COV1D9@ubbclujFX'\n",
    "host='influxdb'\n",
    "port=8086\n",
    "dbname='base'\n",
    "protocol = 'line' #'json'\n",
    "client = DataFrameClient(host, port, user, password, dbname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.drop_database(dbname)\n",
    "client.drop_retention_policy(dbname)\n",
    "client.create_database(dbname)\n",
    "client.create_retention_policy(dbname, '1000d', 1, default=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlipath='../html/'\n",
    "htmlepath='//covid-backup-html.csaladen.es/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles={'HU':\"Magyar\",'RO':'Română','EN':'English'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtitles={titles[t]:t for t in titles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "grafana = \"http://grafana:3000/\"\n",
    "headers = {\n",
    "    'Authorization': 'Bearer eyJrIjoicWNtOWJMWHlGUnd6MFF4ekc5RVcxbFBoNDRmUGoyREkiLCJuIjoianVweXRlciIsImlkIjoxfQ==',\n",
    "    'Accept': 'application/json',\n",
    "    'Content-Type': 'application/json'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(grafana+'api/folders', headers=headers)\n",
    "folders=json.loads(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_id=[f['id'] for f in folders if f['title']=='COVID-19 Romania'][0]\n",
    "# folder_id=[f['id'] for f in folders if f['title']=='COVID-19 Romania Old'][0]\n",
    "# folder_id=[f['id'] for f in folders if f['title']=='Development'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(grafana+'api/search?folderIds='+str(folder_id), headers=headers)\n",
    "dashs=json.loads(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids={rtitles[d['title']]:d['uid'] for d in dashs}\n",
    "iids={rtitles[d['title']]:d['id'] for d in dashs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages=['HU','RO','EN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://docs.google.com/spreadsheets/d/'+open('sheet.txt','r').read()+'/gviz/tq?tqx=out:csv&sheet='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_szotar():\n",
    "    sheet='szotar'\n",
    "    columns=languages+[i+'_description' for i in languages]+[i+'_source' for i in languages]\n",
    "    df=pd.read_csv(url+sheet)\n",
    "    df=df[['ID','UI']+columns]\n",
    "    sheet='minidashboard'\n",
    "    df2=pd.read_csv(url+sheet)\n",
    "    df2=df2[['ID','UI']+columns]\n",
    "    df=pd.concat([df,df2])\n",
    "    szotardf=df.set_index('ID')[columns]\n",
    "    szotar=df.set_index('ID').T.to_dict()\n",
    "    szotarHU=df.set_index('HU',drop=False).T.to_dict()\n",
    "    szotarRO=df.set_index('RO',drop=False).T.to_dict()\n",
    "    szotarEN=df.set_index('EN',drop=False).T.to_dict()\n",
    "    return szotardf,szotar,szotarHU,szotarRO,szotarEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  if sys.path[0] == '':\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  del sys.path[0]\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "szotardf,szotar,szotarHU,szotarRO,szotarEN=get_szotar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push2influx(df,measurement,field_columns,tag_columns,shift=False):\n",
    "    if shift:\n",
    "        df.index+=pd.to_timedelta('12h')\n",
    "    client.query('DROP MEASUREMENT '+measurement)\n",
    "    client.write_points(df, measurement, protocol=protocol,\n",
    "                        field_columns=field_columns,\n",
    "                        tag_columns=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Governance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='governance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(url+sheet)\n",
    "df['date']=pd.to_datetime(df['date'])\n",
    "df=df[df.columns[:13]].set_index('date')\n",
    "df=pd.DataFrame(df[['active','cases','heals','deaths']].stack()).reset_index().set_index('date')\n",
    "df.columns=['type','value']\n",
    "df['value']=df['value'].astype(str).str.replace(',','').astype(float).astype(int)\n",
    "df=df.join(szotardf,on='type')\n",
    "df=pd.DataFrame(df.reset_index().set_index(['date','type','value']).stack()).reset_index().set_index('date')\n",
    "df.columns=['type','value','lang','langtype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['value']\n",
    "tag_columns=['type','lang','langtype']\n",
    "measurement='governance1'\n",
    "push2influx(df,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(url+sheet)\n",
    "df['date']=pd.to_datetime(df['date'])\n",
    "df=df[df.columns[:13]].set_index('date')\n",
    "df=pd.DataFrame(df[['death','heal','case']].stack()).reset_index().set_index('date')\n",
    "df.columns=['type','value']\n",
    "df['value']=df['value'].astype(str).str.replace(',','').astype(float).astype(int)\n",
    "df=df.join(szotardf,on='type')\n",
    "df=pd.DataFrame(df.reset_index().set_index(['date','type','value']).stack()).reset_index().set_index('date')\n",
    "df.columns=['type','value','lang','langtype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['value']\n",
    "tag_columns=['type','lang','langtype']\n",
    "measurement='governance2'\n",
    "push2influx(df,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='countries'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(url+sheet)\n",
    "df['date']=pd.to_datetime(df['date'])\n",
    "df=df[df.columns[:13]].set_index('date')\n",
    "df=df.stack().reset_index().set_index('date')\n",
    "df.columns=['type','value']\n",
    "df['value']=df['value'].astype(str).str.replace(',','').str.replace('%','').astype(float).astype(int)\n",
    "df=df.join(szotardf,on='type')\n",
    "df=pd.DataFrame(df.reset_index().set_index(['date','type','value']).stack()).reset_index().set_index('date')\n",
    "df.columns=['type','value','lang','langtype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['value']\n",
    "tag_columns=['type','lang','langtype']\n",
    "measurement='global1'\n",
    "push2influx(df,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='global'\n",
    "df=pd.read_csv(url+sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=pd.DataFrame(szotardf.stack())\n",
    "ds.columns=['country']\n",
    "ds=ds.reset_index()\n",
    "ds['index2']=ds['ID']+ds['level_1']\n",
    "dc=pd.DataFrame(df.set_index(['Dátum','tag1','Link'])[languages].stack()).reset_index()\n",
    "dc['index1']=dc['tag1']+dc['level_3']\n",
    "dc=dc.set_index('index1').join(ds.set_index('index2')).set_index('Dátum')[[0,'country','Link','level_1']]\n",
    "dc.columns=['desc','country','link','lang']\n",
    "dc.index=pd.to_datetime(dc.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['desc','country','link']\n",
    "tag_columns=['lang']\n",
    "measurement='global2'\n",
    "client.query('DROP MEASUREMENT '+measurement)\n",
    "push2influx(dc,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global automatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries=['France','Germany','Italy','Romania','Spain','US']\n",
    "columns=['fr','de','it','ro','es','us']\n",
    "eus=['Austria','Belgium','Bulgaria','Croatia','Cyprus', 'Czechia', 'Denmark','Estonia',\n",
    "    'Finland', 'France','Germany','Greece','Hungary','Ireland','Italy','Latvia','Lithuania','Luxembourg',\n",
    "    'Malta','Netherlands','Poland', 'Portugal', 'Romania','Slovakia','Slovenia','Spain','Sweden']\n",
    "eus+=['United Kingdom','Andorra','Armenia','Azerbaijan','Belarus','Bosnia and Herzegovina','Georgia', \n",
    "     'Holy See','Iceland','Liechtenstein', 'Moldova','Montenegro','North Macedonia',\n",
    "       'Norway','Russia','San Marino','Switzerland','Turkey','Ukraine','Kosovo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs=[]\n",
    "sheets=['countries_auto_cases','countries_auto_heals','countries_auto_deaths']\n",
    "for i in range(len(sheets)):\n",
    "    sheet=sheets[i]\n",
    "    df=pd.read_csv(url+sheet)\n",
    "    df=df[[c for c in df.columns if 'Unnamed' not in c]]\n",
    "    ww=pd.DataFrame(df.T[2:].astype(float).sum(axis=1))\n",
    "    ww.columns=['ww']\n",
    "    cn=pd.DataFrame(pd.DataFrame(df[df['Country/Region']=='China']).T[2:].astype(float).sum(axis=1))\n",
    "    cn.columns=['cn']\n",
    "    eu=pd.DataFrame(pd.DataFrame(df[df['Country/Region'].isin(eus)]).T[2:].astype(float).sum(axis=1))\n",
    "    eu.columns=['eu']\n",
    "    df=df[df['Province/State'].astype(str)=='nan']\n",
    "    df=df[df['Country/Region'].isin(countries)]\n",
    "    df=df.set_index(\"Country/Region\").T[1:]\n",
    "    df.columns=columns\n",
    "    dfs.append(df.join(eu).join(cn).join(ww))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dfs[0]-dfs[1]-dfs[2]\n",
    "df=df.drop('ro',axis=1)\n",
    "df=df.stack().reset_index()\n",
    "df.columns=['date','type','value']\n",
    "df=df.set_index('date')\n",
    "df['value']=df['value'].astype(int)\n",
    "df=df.join(szotardf,on='type')\n",
    "df=pd.DataFrame(df.reset_index().set_index(['date','type','value']).stack()).reset_index().set_index('date')\n",
    "df.columns=['type','value','lang','langtype']\n",
    "df.index=pd.to_datetime(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['value']\n",
    "tag_columns=['type','lang','langtype']\n",
    "measurement='global3'\n",
    "push2influx(df,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/11/2020\n"
     ]
    }
   ],
   "source": [
    "n=30\n",
    "start=dfs[0][dfs[0]['ro']>30].index.min()\n",
    "print(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dfs[0].rolling(7).mean().diff()\n",
    "das=[]\n",
    "for c in df:\n",
    "    da=pd.DataFrame(df[c][df[c]>n])\n",
    "    da.index=range(len(da))\n",
    "    das.append(da)\n",
    "das=pd.concat(das,axis=1)\n",
    "das.index=[pd.to_datetime(start)+pd.to_timedelta('1D')*i for i in range(len(das))]\n",
    "df=das.stack().reset_index()\n",
    "df.columns=['date','type','value']\n",
    "df=df.set_index('date')\n",
    "df['value']=df['value'].astype(int)\n",
    "df=df.join(szotardf,on='type')\n",
    "df=pd.DataFrame(df.reset_index().set_index(['date','type','value']).stack()).reset_index().set_index('date')\n",
    "df.columns=['type','value','lang','langtype']\n",
    "df.index=pd.to_datetime(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['value']\n",
    "tag_columns=['type','lang','langtype']\n",
    "measurement='global4'\n",
    "push2influx(df,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='governance'\n",
    "df=pd.read_csv(url+sheet)\n",
    "df['date']=pd.to_datetime(df['date'])\n",
    "df=df.set_index('date')[df.columns[10:21]].dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "c='gov_note_econ'\n",
    "dc=df[[c,'gov_note_econ_tag','law','law_link']].dropna(subset=[c]).reset_index()\\\n",
    "            .set_index(c).join(szotardf[languages]).reset_index()\n",
    "dc=pd.DataFrame(dc.set_index(list(dc.columns[:-3])).stack()).reset_index()\n",
    "dc['index']=dc['law']+dc['level_5']\n",
    "dc=dc.set_index('index')\n",
    "dc.columns=['note','date','tag','law','link','lang','desc']\n",
    "ds=szotardf.stack().reset_index()\n",
    "ds['index']=ds['ID']+ds['level_1']\n",
    "ds=ds.set_index('index')\n",
    "ds.columns=['id','lang2','desc2']\n",
    "dc=dc.join(ds).set_index('date')[['desc','tag','link','lang','desc2']]\n",
    "dc['index']=dc['tag']+dc['lang']\n",
    "ds.columns=['id','lang3','desc3']\n",
    "dc=dc.reset_index().set_index('index').join(ds)\n",
    "dc=dc.set_index('date')[['desc','link','lang','desc2','desc3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['desc','desc2','link','desc3']\n",
    "tag_columns=['lang']\n",
    "measurement='social1'\n",
    "push2influx(dc,measurement,field_columns,tag_columns,shift=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "c='gov_note_social'\n",
    "dc=df[[c,'gov_note_social_tag','law','law_link']].dropna(subset=[c]).reset_index()\\\n",
    "            .set_index(c).join(szotardf[languages]).reset_index()\n",
    "dc=pd.DataFrame(dc.set_index(list(dc.columns[:-3])).stack()).reset_index()\n",
    "dc['index']=dc['law']+dc['level_5']\n",
    "dc=dc.set_index('index')\n",
    "dc.columns=['note','date','tag','law','link','lang','desc']\n",
    "ds=szotardf.stack().reset_index()\n",
    "ds['index']=ds['ID']+ds['level_1']\n",
    "ds=ds.set_index('index')\n",
    "ds.columns=['id','lang2','desc2']\n",
    "dc=dc.join(ds).set_index('date')[['desc','tag','link','lang','desc2']]\n",
    "dc['index']=dc['tag']+dc['lang']\n",
    "ds.columns=['id','lang3','desc3']\n",
    "dc=dc.reset_index().set_index('index').join(ds)\n",
    "dc=dc.set_index('date')[['desc','link','lang','desc2','desc3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['desc','desc2','link','desc3']\n",
    "tag_columns=['lang']\n",
    "measurement='social2'\n",
    "push2influx(dc,measurement,field_columns,tag_columns,shift=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "c='gov_note_fin'\n",
    "dc=df[[c,'fin_tag','fin_link','fin_body']].dropna(subset=[c]).reset_index()\\\n",
    "            .set_index(c).join(szotardf[languages]).reset_index()\n",
    "dc=pd.DataFrame(dc.set_index(list(dc.columns[:-3])).stack()).reset_index()\n",
    "dc['index']=dc['fin_body']+dc['level_5']\n",
    "dc=dc.set_index('index')\n",
    "dc.columns=['note','date','tag','link','law','lang','desc']\n",
    "ds=szotardf.stack().reset_index()\n",
    "ds['index']=ds['ID']+ds['level_1']\n",
    "ds=ds.set_index('index')\n",
    "ds.columns=['id','lang2','desc2']\n",
    "dc=dc.join(ds).set_index('date')[['desc','tag','link','lang','desc2']]\n",
    "dc['index']=dc['tag']+dc['lang']\n",
    "ds.columns=['id','lang3','desc3']\n",
    "dc=dc.reset_index().set_index('index').join(ds)\n",
    "dc=dc.set_index('date')[['desc','link','lang','desc2','desc3']]\n",
    "dc['desc']=dc['desc'].str.replace('\"','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['desc','desc2','link','desc3']\n",
    "tag_columns=['lang']\n",
    "measurement='social3'\n",
    "push2influx(dc,measurement,field_columns,tag_columns,shift=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheet='stocks'\n",
    "# df=pd.read_csv(url+sheet)[:-2].drop('Roman allampapir spreadek',axis=1)\n",
    "# sheet='stocks2008'\n",
    "# df2=pd.read_csv(url+sheet)[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dc=pd.DataFrame(df.set_index(['Dátum']).stack()).reset_index()\n",
    "# dc.columns=['date','stock','value']\n",
    "# dc['year']=2020\n",
    "# dc2=pd.DataFrame(df2.set_index(['Dátum','Dátum 2']).stack()).reset_index()\n",
    "# dc2.columns=['date','date2','stock','value']\n",
    "# dc2['year']=2008\n",
    "# dc3=pd.concat([dc,dc2])\n",
    "# dc3=pd.DataFrame(dc3.set_index('stock').join(szotardf).reset_index().set_index(['index','year','date','date2','value']).stack()).reset_index()\n",
    "# dc3=dc3.set_index('date')\n",
    "# dc3.columns=['stock','year','date2','value','lang','langstock']\n",
    "# dc3['value']=dc3['value'].astype(str).str.replace(',','').str.replace('%','').astype(float)\n",
    "# dc3.index=pd.to_datetime(dc3.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# field_columns=['value']\n",
    "# tag_columns=['lang','langstock','year','date2','stock']\n",
    "# measurement='stocks1'\n",
    "# push2influx(dc3,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='stocks_all'\n",
    "df=pd.read_csv(url+sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks=['S&P 500','DAX','BET','STOXX 600','FTSE 100']\n",
    "stocksv=['SP500 volatilitas','DAX volatilitas','BET volatilitas','Stoxx 600 volatilitas','FTSE 100 volatilitas']\n",
    "stocksa=['WTI','Brent']\n",
    "stocksb=['ROBOR3M']\n",
    "stocksc=['Roman allampapir spreadek','Bid/ask 6 honap (%)','Bid/ask 12 honap (%)','Bid/ask 3 ev (%)','Bid/ask 5 ev (%)','Bid/ask 10 ev (%)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "das=[]\n",
    "for stock in stocks+stocksa:\n",
    "    da=df[[stock,list(df.columns)[list(df.columns).index(stock)+1]]].dropna()\n",
    "    da=da.set_index(stock)\n",
    "    da.columns=[stock]\n",
    "    da.index=pd.to_datetime(da.index)\n",
    "    das.append(da)\n",
    "for i,stock in enumerate(stocks):\n",
    "    da=df[[stock,stocksv[i]]].dropna()\n",
    "    da=da.set_index(stock)\n",
    "    da.columns=[stocksv[i]]\n",
    "    da.index=pd.to_datetime(da.index)\n",
    "    das.append(da)\n",
    "das=pd.concat(das,axis=1)\n",
    "for stock in stocksb:\n",
    "    da=df[[stock,list(df.columns)[list(df.columns).index(stock)+1]]].dropna()\n",
    "    da=da.set_index(stock)\n",
    "    da.columns=[stock]\n",
    "    da.index=pd.to_datetime(da.index,dayfirst=True)\n",
    "das=das.join(da)\n",
    "da=df[stocksc].set_index('Roman allampapir spreadek').dropna()*100\n",
    "da.index=pd.to_datetime(da.index,dayfirst=True)\n",
    "das=das.join(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "da1=das.sort_index(ascending=False)[:'2020-02-26']\n",
    "da2=das.sort_index(ascending=False)[:'2008-09-16'].sort_index(ascending=False).tail(len(da1))\n",
    "da2.index=da1.index\n",
    "\n",
    "dc=pd.DataFrame(da1.stack()).reset_index()\n",
    "dc.columns=['date','stock','value']\n",
    "dc['year']=2020\n",
    "dc2=pd.DataFrame(da2.stack()).reset_index()\n",
    "dc2.columns=['date','stock','value']\n",
    "dc2['year']=2008\n",
    "dc3=pd.concat([dc,dc2])\n",
    "dc3=pd.DataFrame(dc3.set_index('stock').join(szotardf).reset_index().set_index(['index','year','date','value']).stack()).reset_index()\n",
    "dc3=dc3.set_index('date')\n",
    "dc3.columns=['stock','year','value','lang','langstock']\n",
    "dc3['value']=dc3['value'].astype(str).str.replace(',','').str.replace('%','').astype(float)\n",
    "dc3.index=pd.to_datetime(dc3.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['value']\n",
    "tag_columns=['lang','langstock','year','stock']\n",
    "measurement='stocks1'\n",
    "push2influx(dc3,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='exchangerates'\n",
    "df=pd.read_csv(url+sheet)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc=pd.DataFrame(df.set_index(['date']).stack()).reset_index()\n",
    "dc.columns=['date','stock','value']\n",
    "dc=pd.DataFrame(dc.set_index('stock').join(szotardf)\\\n",
    ".reset_index().set_index(['index','date','value']).stack()).reset_index()\n",
    "dc=dc.set_index('date')\n",
    "dc.columns=['stock','value','lang','langstock']\n",
    "dc['value']=dc['value'].astype(str).str.replace(',','').str.replace('%','').astype(float)\n",
    "dc.index=pd.to_datetime(dc.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['value']\n",
    "tag_columns=['lang','langstock','stock']\n",
    "measurement='stocks2'\n",
    "push2influx(dc,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='firms'\n",
    "df=pd.read_csv(url+sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "dc=df[['Friendly name','Üzleti forgalom, 2018 (RON)','Alkalmazottak száma, 2018 (fő)',\n",
    "       'Részarány az országos üzleti forgalomból, 2018 (%)','Részarány az iparági üzleti forgalomból, 2018 (%)']]\n",
    "dc.columns=['name','revenue','employees','share','indshare']\n",
    "dc['date']=pd.to_datetime('2020-04-05')\n",
    "dc=dc.set_index('date')\n",
    "dc['employees']=dc['employees'].astype(str).str.replace(',','').astype(float).astype(int)\n",
    "dc['revenue']=dc['revenue'].astype(str).str.replace(',','').astype(float).astype(int)\n",
    "dc['share']=dc['share'].astype(str).str.replace('%','').astype(float)\n",
    "dc['indshare']=dc['indshare'].astype(str).str.replace('%','').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['revenue','employees','share','indshare']\n",
    "tag_columns=['name']\n",
    "measurement='firms1'\n",
    "push2influx(dc,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firms2 at page bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc2=df[['Friendly name','Higiénia, távolságtartás', 'Informálás', 'Adomány',\n",
    "       'Üzleti utak leállítása vagy korlátozása',\n",
    "       'Home office, rugalmas munkaidő', 'Részleges leállás', 'Teljes leállás',\n",
    "       'Személyzet csökkentése (akár somai tehnic-el)',\n",
    "       'Támogatás (pl. telefonos vonal stb.)', 'Testhőmérséklet követése',\n",
    "       'Egyéb',\n",
    "       'Súlyosság (4 = nagyon súlyos, 3 = súlyos, 2 = átlagos, 1 = gyenge)']].set_index('Friendly name')\n",
    "dc3=dc.reset_index().set_index('name').join(dc2).reset_index().set_index('date')\n",
    "dc3.columns=['name','revenue','employees','share','indshare','higenia',\n",
    "'informalas',\n",
    "'adomany',\n",
    "'uzleti_utak',\n",
    "'home_office',\n",
    "'reszleges_leallas',\n",
    "'teljes_leallas',\n",
    "'szemelyzet_csok',\n",
    "'tamogatas',\n",
    "'testho',\n",
    "'egyebi',\n",
    "'sulyos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=list(dc3.columns[1:])\n",
    "tag_columns=['name']\n",
    "measurement='firms3'\n",
    "push2influx(dc3.fillna(0),measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc2=df[['Friendly name','COVID-19 terjedésének megakadályozása','Alkalmazottak egészségének védelme','Ügyfelek egészségének védelme','Csökkent kereslet','Támogatás (egészségügyi, kapcsolattartás)',\n",
    "        'A vállalat lépéseinek indoka(i) HU','A vállalat lépéseinek indoka(i) RO','A vállalat lépéseinek indoka(i) EN',\n",
    "       'Súlyosság (4 = nagyon súlyos, 3 = súlyos, 2 = átlagos, 1 = gyenge)']].set_index('Friendly name')\n",
    "dc3=dc.reset_index().set_index('name').join(dc2).reset_index().set_index('date')\n",
    "dc3.columns=['name','revenue','employees','share','indshare','terjedes',\n",
    "'alkegeszseg',\n",
    "'ugyfegeszseg',\n",
    "'csokkereslet',\n",
    "'tamogatasek',\n",
    "'HU','RO','EN',\n",
    "'sulyos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc3=dc3.reset_index().set_index(['date','name','revenue','employees','share','indshare','terjedes',\n",
    "'alkegeszseg',\n",
    "'ugyfegeszseg',\n",
    "'csokkereslet',\n",
    "'tamogatasek',\n",
    "'sulyos']).stack().reset_index().set_index('date')\n",
    "dc3.columns=['name','revenue','employees','share','indshare','terjedes',\n",
    "'alkegeszseg',\n",
    "'ugyfegeszseg',\n",
    "'csokkereslet',\n",
    "'tamogatasek',\n",
    "'sulyos',\n",
    "'lang',\n",
    "'lepesindok']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['revenue','employees','share','indshare','terjedes',\n",
    "'alkegeszseg',\n",
    "'ugyfegeszseg',\n",
    "'csokkereslet',\n",
    "'tamogatasek',\n",
    "'sulyos',\n",
    "'lepesindok']\n",
    "tag_columns=['name','lang']\n",
    "measurement='firms4'\n",
    "push2influx(dc3.fillna(0),measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='minidashboard'\n",
    "dm=pd.read_csv(url+sheet)\n",
    "sheet='governance'\n",
    "df=pd.read_csv(url+sheet)\n",
    "df['date']=pd.to_datetime(df['date'])\n",
    "df=df[df.columns[:10]].set_index('date')\n",
    "for i in dm.set_index('ID')['UI'].iteritems():\n",
    "    df[i[0]]=i[1]\n",
    "sheet='employmentdata'\n",
    "de=pd.read_csv(url+sheet)\n",
    "de['date']=pd.to_datetime(de['date'])\n",
    "de=de[de.columns[:3]].set_index('date')\n",
    "de.columns=['felbontott','felfuggesztett']\n",
    "df=df.join(de.ffill())\n",
    "sheet='bordercrossings'\n",
    "db=pd.read_csv(url+sheet)\n",
    "db['date']=pd.to_datetime(db['Dátum'])\n",
    "db=db.set_index('date')[['Változás ']]\n",
    "db.columns=['border']\n",
    "df=df.join(db)\n",
    "for c in df.columns:\n",
    "    df[c]=df[c].astype(str).str.replace(',','').str.replace('%','').astype(float)\n",
    "sheet='exchangerates'\n",
    "dx=pd.read_csv(url+sheet)\n",
    "dx=dx[['date','EUR - RON (megváltozás)']][5:-1]\n",
    "dx['date']=pd.to_datetime(dx['date'])\n",
    "dx=dx.set_index('date')\n",
    "dx.columns=['xch']\n",
    "dx['xch']=dx['xch'].astype(str).str.replace(',','').str.replace('%','').astype(float).sort_index().cumsum()\n",
    "df=df.join(dx)\n",
    "df['xch']=df['xch'].ffill()\n",
    "sheet='stocks_all'\n",
    "dk=pd.read_csv(url+sheet)[['BET', 'BET hozam']].dropna()\n",
    "dk['date']=pd.to_datetime(dk['BET'])\n",
    "dk=dk.set_index('date').drop('BET',axis=1)\n",
    "dk.columns=['bet']\n",
    "dk=dk.reindex(df.index)\n",
    "dk['bet']=dk['bet'].astype(str).str.replace(',','').str.replace('%','').astype(float).sort_index().cumsum()\n",
    "df=df.join(dk)\n",
    "df['border']=df['border'].sort_index()\n",
    "df['border']=[df['border'][:i].mean() for i in df['border'].index]\n",
    "df=df[:pd.to_datetime('now')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=list(df.columns)\n",
    "tag_columns=[]\n",
    "measurement='governance3'\n",
    "push2influx(df,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='EcMonitor'\n",
    "df=pd.read_csv(url+sheet).dropna(how='all',axis=1)\n",
    "# df=df.set_index('Date').dropna(how='all').stack().reset_index()\n",
    "# df.columns=['item','month','value']\n",
    "# dfs=[]\n",
    "# for d in pd.date_range(pd.to_datetime('2020-02-26'),pd.to_datetime('now')):\n",
    "#     df['date']=d\n",
    "#     dfs.append(df)\n",
    "# dfs=pd.concat(dfs).set_index('date')\n",
    "# dfs.index=pd.to_datetime(dfs.index)\n",
    "df['Time']=pd.to_datetime('2020-04-05')\n",
    "df=df.set_index('Time')\n",
    "df.columns=['c'+str(i) for i in range(len(df.columns))]\n",
    "df=df.set_index('c0',append=True).astype(float).dropna(how='all').reset_index().set_index('Time')\n",
    "df['index']=range(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=list(df.columns[1:])\n",
    "tag_columns=df.columns[0]\n",
    "measurement='macro'\n",
    "push2influx(df,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grafana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa={'status':'bar-chart', 'global':'globe','governance':'gavel','stocks':'line-chart','firms':'car','data':'database',\n",
    "    'industry':'industry','exports':'sign-out','credits':'coffee','others':'ellipsis-h','counties':'street-view','macro':'forward'}\n",
    "ids={8:'logo',90:'flogo', 10:'title',6:'main_content',12:'status', 19:'global', 18:'governance', 17:'stocks', 16:'firms', 15:'industry', \n",
    "     14:'counties',13:'footer',57:'footer2',23:'lang',66:'credits',82:'report',85:'others',93:'update',94:'data',97:'macro'}\n",
    "plots={21:'governance_plot1',24:'governance_plot2',22:'global_plot1',32:'social_plot1',37:'social_plot3',36:'social_plot5',\n",
    "      55:'stock',54:'none',42:'stock_plot3',56:'stock_plot4',41:'stock',43:'stock',44:'stock',46:'stock',45:'stock',\n",
    "      48:'stock',49:'stock',50:'stock',51:'stock',53:'stock',61:'firms3',63:'firms5',96:'stock_plot5',95:'stock_plot6'}\n",
    "singlestats={68:'status_plot1',69:'status_plot2',70:'status_plot3',71:'status_plot4',72:'status_plot5',73:'status_plot6',74:'status_plot7',\n",
    "            75:'status_plot8',76:'status_plot9',77:'status_plot10',78:'status_plot11',79:'status_plot12',80:'status_plot13',88:'status_plot10',89:'matrix',\n",
    "            91:'megyecase',98:'GDP growth vs. market and DFM estimates',100:'Economic activity indicators (YoY%)',99:'macro_scatter1',\n",
    "            101:'Sentiment indicators (index)',102:'Labour market indicators',104:'Prices, money and credit (YoY%)',103:'macro_scatter2'}\n",
    "heatmaps={59:'firms1',60:'firms2'}\n",
    "tables={31:'global_plot2',33:'social_plot2',39:'social_plot4',38:'social_plot6',62:'firms4',64:'firms6',65:'firms7'}\n",
    "tooltips=[64,65]\n",
    "legends={64:86,65:87}\n",
    "legendtext={legends[i]:'' for i in tooltips}\n",
    "kiosk=''#'?kiosk'\n",
    "strftimes={'HU':'%Y.%m.%d','RO':'%d/%m/%Y','EN':'%Y-%m-%d'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# szotardf,szotar,szotarHU,szotarRO,szotarEN=get_szotar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=json.loads(open('HU.json','r').read())\n",
    "# response = requests.get(grafana+'api/dashboards/uid/'+uids['HU'], headers=headers)\n",
    "# response = requests.get(grafana+'api/dashboards/uid/ui', headers=headers)\n",
    "response = requests.get(grafana+'api/dashboards/uid/hu', headers=headers)\n",
    "# response = requests.get(grafana+'api/dashboards/uid/hu-dev', headers=headers)\n",
    "model=json.loads(response.content)['dashboard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in model['panels']:\n",
    "#     print (p['id'],p['type'],p['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HU\n",
      "<Response [200]> b'{\"id\":2,\"slug\":\"magyar\",\"status\":\"success\",\"uid\":\"hu\",\"url\":\"/d/hu/magyar\",\"version\":266}'\n",
      "RO\n",
      "<Response [200]> b'{\"id\":4,\"slug\":\"romana\",\"status\":\"success\",\"uid\":\"ro\",\"url\":\"/d/ro/romana\",\"version\":177}'\n",
      "EN\n",
      "<Response [200]> b'{\"id\":3,\"slug\":\"english\",\"status\":\"success\",\"uid\":\"en\",\"url\":\"/d/en/english\",\"version\":174}'\n"
     ]
    }
   ],
   "source": [
    "for lang in languages:\n",
    "    print(lang)    \n",
    "    for panel in model['panels']:\n",
    "        if 'type' in panel:\n",
    "            panel['description']=''\n",
    "            if panel['type']=='text':\n",
    "                if panel['id'] in ids:\n",
    "                    i=ids[panel['id']]\n",
    "                    if i=='logo':\n",
    "                        panel['content']='<a target=\"_blank\" href=\"'+\\\n",
    "                        szotar['logo_link'][lang]+'\"><img id=\"logo\" class=\"logo\" alt=\"'+\\\n",
    "                        szotar['logo_alt'][lang]+'\" src=\"'+htmlepath+\\\n",
    "                        szotar['logo_img'][lang]+'\" style=\"height:70px!important;width:200px!important;\"/></a>'\n",
    "                    elif i=='flogo':\n",
    "                        panel['content']='<a target=\"_blank\" href=\"'+\\\n",
    "                        szotar['flogo_link'][lang]+'\"><img id=\"flogo\" class=\"flogo\" alt=\"'+\\\n",
    "                        szotar['flogo_alt'][lang]+'\" src=\"'+htmlepath+\\\n",
    "                        szotar['flogo_img'][lang]+'\" style=\"height:80px!important;width:330px!important;\"/></a>'\n",
    "                    elif i=='lang':\n",
    "                        panel['content']='<br><div class=\"lang\" style=\"text-align: left\">'\n",
    "                        for l in ['RO','HU','EN']:\n",
    "                            # panel['content']+='&nbsp;&nbsp;<a target=\"_self\" href=\"/d/'+uids[l]+'?var-lang='+lang+'\">'+l+'</a>'\n",
    "                            panel['content']+='&nbsp;&nbsp;<a target=\"_self\" href=\"/d/'+uids[l]+kiosk+'\">'+l+'</a>'\n",
    "                        panel['content']+='</div>'\n",
    "                    elif i=='title':\n",
    "                        panel['content']='<div style=\"text-align:left;\"><h1>'+str(szotar['title'][lang])+'</h1><h3> '+str(szotar['subtitle'][lang])+'</h3></div>'\n",
    "                    elif i in ['main_content','footer','footer2']:\n",
    "                        panel['content']=str(szotar[i][lang])\n",
    "                    elif i in ['credits','others','data']:\n",
    "                        panel['content']='<p><h4><i class=\"fa fa-'+fa[i]+'\"></i>&nbsp;&nbsp;'+str(szotar[i][lang])+'</h4><div>'+str(szotar[i+'_content'][lang])+'</div></p>'\n",
    "                    elif i=='report':\n",
    "                        panel['content']='<p><span style=\"font-size:26px;padding-right:10px;color:#F2CC0C;\"><b>'+str(szotar[i]['UI'][1:])+'</b></span><span style=\"font-size:18px;\">'+str(szotar[i][lang])+'</span></p>'\n",
    "                    elif i=='update':\n",
    "                        panel['content']='<div style=\"text-align:right;\"><i class=\"fa fa-clock\"></i>'+str(szotar['update'][lang])+' <b>'+pd.to_datetime('now').strftime(strftimes[lang])+'</b></div>'\n",
    "                    else:\n",
    "                        panel['content']='<p><h2><i class=\"fa fa-'+fa[i]+'\"></i>&nbsp;&nbsp;'+str(szotar[i][lang])+'</h2><div>'+str(szotar[i+'_content'][lang])+'</div></p>'\n",
    "                elif panel['id'] in legendtext:\n",
    "                    panel['content']=legendtext[panel['id']]\n",
    "            elif panel['type']=='graph':\n",
    "                if panel['id'] in plots:\n",
    "                    i=plots[panel['id']]\n",
    "                    if i=='stock':\n",
    "                        if lang in ['HU','RO']:\n",
    "                            description=str(szotarHU[panel['title']][lang+'_description'])\n",
    "                            source=str(szotarHU[panel['title']][lang+'_source']) \n",
    "                            panel['title']=szotarHU[panel['title']][lang]\n",
    "                        else:\n",
    "                            description=str(szotarRO[panel['title']][lang+'_description'])\n",
    "                            source=str(szotarRO[panel['title']][lang+'_source'])     \n",
    "                            panel['title']=szotarRO[panel['title']][lang]  \n",
    "                        if description not in ['nan','XXX']:\n",
    "                            panel['description']=description\n",
    "                        if source not in ['nan','XXX']:\n",
    "                            panel['description']+='  \\n'+source\n",
    "                    elif i!='none':\n",
    "                        panel['title']=szotar[i][lang]\n",
    "                        description=str(szotar[i][lang+'_description'])\n",
    "                        source=str(szotar[i][lang+'_source'])    \n",
    "                        if description not in ['nan','XXX']:\n",
    "                            panel['description']=description\n",
    "                        if source not in ['nan','XXX']:\n",
    "                            panel['description']+='  \\n'+source\n",
    "                    for s in panel['seriesOverrides']:\n",
    "                        if s['alias'] not in ['/./']:\n",
    "                            if lang in ['HU','RO']:\n",
    "                                s['alias']=szotarHU[s['alias']][lang]\n",
    "                            else:\n",
    "                                s['alias']=szotarRO[s['alias']][lang]\n",
    "                    for s in panel['targets']:\n",
    "                        if lang in ['HU','RO']:\n",
    "                            sz={s:szotarHU[s] for s in szotarHU if szotarHU[s]['UI']=='replace'}\n",
    "                            if s['alias'] in sz:\n",
    "                                s['alias']=sz[s['alias']][lang]\n",
    "                        else:\n",
    "                            sz={s:szotarRO[s] for s in szotarRO if szotarRO[s]['UI']=='replace'}\n",
    "                            if s['alias'] in sz:\n",
    "                                s['alias']=szotarRO[s['alias']][lang]\n",
    "                    \n",
    "            elif panel['type'] in ['singlestat','ryantxu-ajax-panel']:\n",
    "                if panel['id'] in singlestats:\n",
    "                    i=singlestats[panel['id']]\n",
    "                    panel['title']=szotar[i][lang]\n",
    "                    description=str(szotar[i][lang+'_description'])\n",
    "                    source=str(szotar[i][lang+'_source'])    \n",
    "                    if description not in ['nan','XXX']:\n",
    "                        panel['description']=description\n",
    "                    if source not in ['nan','XXX']:\n",
    "                        panel['description']+='  \\n'+source\n",
    "            elif panel['type']=='savantly-heatmap-panel':\n",
    "                if panel['id'] in heatmaps:\n",
    "                    i=heatmaps[panel['id']]\n",
    "                    if lang in ['HU','RO']:\n",
    "                        panel['title']=szotarHU[panel['title']][lang]\n",
    "                    else:\n",
    "                        panel['title']=szotarRO[panel['title']][lang]\n",
    "                    description=str(szotar[i][lang+'_description'])\n",
    "                    source=str(szotar[i][lang+'_source'])    \n",
    "                    if description not in ['nan','XXX']:\n",
    "                        panel['description']=description\n",
    "                    if source not in ['nan','XXX']:\n",
    "                        panel['description']+='  \\n'+source  \n",
    "            elif panel['type']=='table':\n",
    "                if panel['id'] in tables:\n",
    "                    i=tables[panel['id']]\n",
    "                    panel['title']=szotar[i][lang]\n",
    "                    legend='<table class=\"legend\"><tr><td>&nbsp;</td><td>&nbsp;</td></tr>'\n",
    "                    for s in panel['styles']:\n",
    "                        if lang in ['HU','RO']:\n",
    "                            sz={s:szotarHU[s] for s in szotarHU if szotarHU[s]['UI']=='replace'}\n",
    "                            if s['alias'] in sz:\n",
    "                                s['alias']=sz[s['alias']][lang]\n",
    "                        else:\n",
    "                            sz={s:szotarRO[s] for s in szotarRO if szotarRO[s]['UI']=='replace'}\n",
    "                            if s['alias'] in sz:\n",
    "                                s['alias']=szotarRO[s['alias']][lang]\n",
    "                        if panel['id'] in tooltips:\n",
    "                            if 'link' in s:\n",
    "                                if s['link']:\n",
    "                                    s['linkTooltip']=szotar[s['pattern']][lang]\n",
    "                                    legend+='<tr><td>'+s['alias']+'</td><td>'+szotar[s['pattern']][lang]+'</td></tr>'\n",
    "                    if panel['id'] in tooltips:\n",
    "                        legendtext[legends[panel['id']]]=legend\n",
    "                    description=str(szotar[i][lang+'_description'])\n",
    "                    source=str(szotar[i][lang+'_source'])    \n",
    "                    if description not in ['nan','XXX']:\n",
    "                        panel['description']=description\n",
    "                    if source not in ['nan','XXX']:\n",
    "                        panel['description']+='  \\n'+source\n",
    "                                    \n",
    "    model['title']=titles[lang]\n",
    "    model['templating']['list'][0]['current']['text']=lang\n",
    "    model['templating']['list'][0]['current']['value']=lang\n",
    "    for option in model['templating']['list'][0]['options']:\n",
    "        option['selected']=False\n",
    "        if option['value']==lang:\n",
    "            option['selected']=True\n",
    "    open(lang+'.json','w').write(json.dumps(model))\n",
    "    r=requests.post(grafana+'api/dashboards/db', headers=headers, json={\"dashboard\":model,\n",
    "                                                                    \"folderId\": folder_id,\n",
    "                                                                    \"overwrite\": True\n",
    "                                                                   })\n",
    "    print(r,r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purge_annotations(tag, dash):\n",
    "    if tag=='all':\n",
    "        r=requests.get(grafana+'api/annotations?limit=10000&dashboardId='+\n",
    "                       str(dash), headers=headers)\n",
    "    else:\n",
    "        r=requests.get(grafana+'api/annotations?limit=10000&tags='+tag+\n",
    "                       '&dashboardId='+str(dash), headers=headers)\n",
    "    annotations=json.loads(r.content)\n",
    "    for a in annotations:\n",
    "        r=requests.delete(grafana+'api/annotations/'+str(a['id']), headers=headers)\n",
    "    print(len(annotations),'annotations purged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_annotations(a):\n",
    "    return requests.post(grafana+'api/annotations', headers=headers, json=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "forras={'HU':'forrás','RO':'sursa','EN':'source'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HU\n",
      "191 annotations purged\n",
      "RO\n",
      "191 annotations purged\n",
      "EN\n",
      "191 annotations purged\n"
     ]
    }
   ],
   "source": [
    "for lang in ['HU','RO','EN']:\n",
    "    print(lang)\n",
    "    purge_annotations('all',iids[lang])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='global'\n",
    "df=pd.read_csv(url+sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 annotations purged\n",
      "HU\n",
      "0 annotations purged\n",
      "RO\n",
      "0 annotations purged\n",
      "EN\n"
     ]
    }
   ],
   "source": [
    "mtag='global'\n",
    "for lang in ['HU','RO','EN']:\n",
    "    purge_annotations(mtag,iids[lang])\n",
    "    for i in df.T.to_dict().values():\n",
    "        tags=[mtag]\n",
    "        if str(i['tag1'])!='nan':\n",
    "            tags.append(szotar[str(i['tag1'])][lang])\n",
    "        if str(i['tag2'])!='nan':\n",
    "            tags.append(szotar[str(i['tag2'])][lang])\n",
    "        a={\n",
    "          \"dashboardId\":iids[lang],\n",
    "          \"panelId\":22,\n",
    "          \"time\":int(pd.to_datetime(i['Dátum']).strftime(\"%s\"))*1000,\n",
    "          # \"timeEnd\":int((pd.to_datetime(i['Dátum'])+pd.to_timedelta('9h')).strftime(\"%s\"))*1000,\n",
    "          \"tags\":tags,\n",
    "          \"text\":'<div class=\"annotation_\"'+mtag+'>'+i[lang]+'</div><a target=\"_blank\" href=\"'+i['Link']+'\">'+forras[lang]+'</a>',\n",
    "        }\n",
    "        post_annotations(a)\n",
    "    print(lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Governance - economic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='governance'\n",
    "df=pd.read_csv(url+sheet)\n",
    "dc=df.dropna(subset=['gov_note_econ'])[['gov_note_econ','gov_note_econ_tag','date','law_link']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 annotations purged\n",
      "HU\n",
      "0 annotations purged\n",
      "RO\n",
      "0 annotations purged\n",
      "EN\n"
     ]
    }
   ],
   "source": [
    "mtag='economic'\n",
    "for lang in ['HU','RO','EN']:\n",
    "    purge_annotations(mtag, iids[lang])\n",
    "    for i in dc.T.to_dict().values():\n",
    "        tags=[mtag]\n",
    "        if str(i['gov_note_econ_tag'])!='nan':\n",
    "            tags.append(szotar[str(i['gov_note_econ_tag'])][lang])\n",
    "        a={\n",
    "          \"dashboardId\":iids[lang],\n",
    "          \"panelId\":32,\n",
    "          \"time\":int(pd.to_datetime(i['date']).strftime(\"%s\"))*1000,\n",
    "          # \"timeEnd\":int((pd.to_datetime(i['date'])+pd.to_timedelta('9h')).strftime(\"%s\"))*1000,\n",
    "          \"tags\":tags,\n",
    "          \"text\":'<div class=\"annotation_\"'+mtag+'>'+szotar[i['gov_note_econ']][lang]+\\\n",
    "            '</div><a target=\"_blank\" href=\"'+i['law_link']+'\">'+forras[lang]+'</a>',\n",
    "        }\n",
    "        post_annotations(a)\n",
    "    print(lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Governance - social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='governance'\n",
    "df=pd.read_csv(url+sheet)\n",
    "dc=df.dropna(subset=['gov_note_social'])[['gov_note_social','gov_note_social_tag','date','law_link']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 annotations purged\n",
      "HU\n",
      "0 annotations purged\n",
      "RO\n",
      "0 annotations purged\n",
      "EN\n"
     ]
    }
   ],
   "source": [
    "mtag='social'\n",
    "for lang in ['HU','RO','EN']:\n",
    "    purge_annotations(mtag, iids[lang])\n",
    "    for i in dc.T.to_dict().values():\n",
    "        tags=[mtag]\n",
    "        if str(i['gov_note_social_tag'])!='nan':\n",
    "            tags.append(szotar[str(i['gov_note_social_tag'])][lang])\n",
    "        a={\n",
    "          \"dashboardId\":iids[lang],\n",
    "          \"panelId\":37,\n",
    "          \"time\":int(pd.to_datetime(i['date']).strftime(\"%s\"))*1000,\n",
    "          # \"timeEnd\":int((pd.to_datetime(i['date'])+pd.to_timedelta('9h')).strftime(\"%s\"))*1000,\n",
    "          \"tags\":tags,\n",
    "          \"text\":'<div class=\"annotation_\"'+mtag+'>'+szotar[i['gov_note_social']][lang]+\\\n",
    "            '</div><a target=\"_blank\" href=\"'+i['law_link']+'\">'+forras[lang]+'</a>',\n",
    "        }\n",
    "        post_annotations(a)\n",
    "    print(lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Governance - financial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='governance'\n",
    "df=pd.read_csv(url+sheet)\n",
    "dc=df.dropna(subset=['gov_note_fin'])[['gov_note_fin','fin_tag','date','fin_body','fin_link']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 annotations purged\n",
      "HU\n",
      "0 annotations purged\n",
      "RO\n",
      "0 annotations purged\n",
      "EN\n"
     ]
    }
   ],
   "source": [
    "mtag='financial'\n",
    "for lang in ['HU','RO','EN']:\n",
    "    purge_annotations(mtag, iids[lang])\n",
    "    for i in dc.T.to_dict().values():\n",
    "        tags=[mtag]\n",
    "        if str(i['fin_body'])!='nan':\n",
    "            tags.append(szotar[str(i['fin_body'])][lang])\n",
    "        if str(i['fin_tag'])!='nan':\n",
    "            tags.append(szotar[str(i['fin_tag'])][lang])\n",
    "        a={\n",
    "          \"dashboardId\":iids[lang],\n",
    "          \"panelId\":36,\n",
    "          \"time\":int(pd.to_datetime(i['date']).strftime(\"%s\"))*1000,\n",
    "          # \"timeEnd\":int((pd.to_datetime(i['date'])+pd.to_timedelta('9h')).strftime(\"%s\"))*1000,\n",
    "          \"tags\":tags,\n",
    "          \"text\":'<div class=\"annotation_\"'+mtag+'>'+szotar[i['gov_note_fin']][lang]+\\\n",
    "            '</div><a target=\"_blank\" href=\"'+i['fin_link']+'\">'+forras[lang]+'</a>',\n",
    "        }\n",
    "        post_annotations(a)\n",
    "    print(lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='events'\n",
    "df=pd.read_csv(url+sheet)\n",
    "dc=df[['Friendly name','Date','HU', 'RO','EN','Link', 'Link.1', 'Link.2']]\n",
    "dc.columns=['name','date','HU','RO','EN','link1','link2','link3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='firms'\n",
    "df=pd.read_csv(url+sheet)\n",
    "de=df[['Friendly name', 'RO CAEN sectiune','HU CAEN sectiune', 'EN CAEN sectiune']]\n",
    "de.columns=['name','RO', 'HU','EN']\n",
    "de=de.set_index('name').stack().reset_index()\n",
    "de.columns=['name','lang','industry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc=dc.set_index(['name','date','link1','link2','link3']).stack().reset_index()\n",
    "dc.columns=['name','date','link1','link2','link3','lang','steps']\n",
    "dc=dc.set_index(['name','lang']).join(de.set_index(['name','lang'])).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "annos1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 annotations purged\n",
      "0 annotations purged\n",
      "HU\n",
      "0 annotations purged\n",
      "0 annotations purged\n",
      "RO\n",
      "0 annotations purged\n",
      "0 annotations purged\n",
      "EN\n"
     ]
    }
   ],
   "source": [
    "for lang in ['HU','RO','EN']:\n",
    "    purge_annotations('firms', iids[lang])\n",
    "    purge_annotations('facebook', iids[lang])\n",
    "    dc3=dc[dc['lang']==lang]\n",
    "    ds={}\n",
    "    for i in dc3.T.to_dict().values():\n",
    "        links=''\n",
    "        links1=['']\n",
    "        mtag='firms'\n",
    "        pid=61\n",
    "        atag=szotar['vallalati'][lang]\n",
    "        for link in ['link1','link2','link3']:\n",
    "            l=str(i[link])\n",
    "            if l!='nan':\n",
    "                if links=='':\n",
    "                    links='<a target=\"_blank\" href=\"'+l+'\">'+forras[lang]+'</a>'\n",
    "                    links1[0]=l\n",
    "                    if 'facebook' in l:\n",
    "                        mtag='facebook'\n",
    "                        pid=63\n",
    "                        atag='Facebook'\n",
    "                else:\n",
    "                    links+='; <a target=\"_blank\" href=\"'+l+'\">'+forras[lang]+'</a>'\n",
    "                    links1.append(l)\n",
    "        tags=[mtag]\n",
    "        if str(i['name'])!='nan':\n",
    "            tags.append(str(i['name']))\n",
    "        if str(i['industry'])!='nan':\n",
    "            tags.append(str(i['industry']))\n",
    "        d=str(i['date'])\n",
    "        if d=='nan':\n",
    "            tags.append(str('no date'))\n",
    "            d='2020-03-10'\n",
    "        if d not in ds:\n",
    "            ds[d]=pd.to_datetime(d)\n",
    "            t=(ds[d])\n",
    "        else:\n",
    "            ds[d]=ds[d]+pd.to_timedelta('193m')\n",
    "            t=(ds[d])\n",
    "        a={\n",
    "          \"dashboardId\":iids[lang],\n",
    "          \"panelId\":pid,\n",
    "          \"time\":int(t.strftime(\"%s\"))*1000,\n",
    "          # \"timeEnd\":int((pd.to_datetime(t)+pd.to_timedelta('9h')).strftime(\"%s\"))*1000,\n",
    "          \"tags\":tags,\n",
    "          \"text\":'<div><b>'+str(i['name'])+'</b></div><div class=\"annotation_\"'+mtag+'>'+i['steps']+\\\n",
    "            '</div>'+links,\n",
    "        }\n",
    "        post_annotations(a)\n",
    "        annos1.append({'name':str(i['name']),'date':t,'event':i['steps'],'link':links1[0],'type':atag,'lang':lang})\n",
    "    print(lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Push annos to Influx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "da=pd.DataFrame(annos1).set_index('date')\n",
    "da['event']=da['event'].str.replace('\"','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "da3=[]\n",
    "for lang in ['HU','RO','EN']:\n",
    "    da2=da[da['lang']==lang].sort_index(ascending=False)\n",
    "    ds={}\n",
    "    ts=[]\n",
    "    for d in da2.index:\n",
    "        if d not in ds:\n",
    "            ds[d]=pd.to_datetime(d)\n",
    "            t=(ds[d])\n",
    "        else:\n",
    "            ds[d]=ds[d]+pd.to_timedelta('193m')\n",
    "            t=(ds[d])\n",
    "        ts.append(t)\n",
    "    da2.index=ts\n",
    "    da3.append(da2)\n",
    "da3=pd.concat(da3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['name','event','link','type']\n",
    "tag_columns=['lang']\n",
    "measurement='firms2'\n",
    "push2influx(da3,measurement,field_columns,tag_columns,shift=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Industry county map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "georo=json.loads(open(htmlipath+'panels/romania-counties.json','r').read())\n",
    "georoco={i['properties']['NAME_1']:i['properties']['ID_1'] for i in georo['objects']['ROU_adm1']['geometries']}   \n",
    "georoco['București']=georoco['Bucharest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='industry_county'\n",
    "df=pd.read_csv(url+sheet)[:-2]\n",
    "df=df[df.columns[:4]]\n",
    "df.columns=['HU','RO','EN','value']\n",
    "df['value']=df['value'].str.replace('%','').astype(float)\n",
    "df=df.set_index('RO').join(pd.DataFrame(georoco,index=['county']).T).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in languages:\n",
    "    dc=df[[lang,'value','county']]\n",
    "    dc.columns=['county','value','id']\n",
    "    open(htmlipath+'panels/county_'+lang+'.json','w').write(json.dumps(list(dc.T.to_dict().values())))\n",
    "    # open('county_'+lang+'.json','w').write(json.dumps(list(dc.T.to_dict().values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case county map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='counties_current'\n",
    "dg=pd.read_csv(url+sheet, header=None)\n",
    "dgl=dg[[1,4]].set_index(4).T.to_dict()\n",
    "dgl['Dambovita']=dgl['Dâmbovita']\n",
    "dgl['Szucsáva']=dgl['Suceava']\n",
    "dgl['Galac']=dgl['Galati']\n",
    "dgl['Valcea']=dgl['Vâlcea']\n",
    "dfl=df[languages+['county']].set_index('HU')\n",
    "dh=dfl.join(pd.DataFrame(dgl).T).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in languages:\n",
    "    dc=dh[[lang,1,'county']]\n",
    "    dc.columns=['county','value','id']\n",
    "    open(htmlipath+'panels/county2_'+lang+'.json','w').write(json.dumps(list(dc.T.to_dict().values())))\n",
    "    # open('county2_'+lang+'.json','w').write(json.dumps(list(dc.T.to_dict().values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='matrix'\n",
    "df=pd.read_csv(url+sheet)[:-1]\n",
    "df=df[['IND HU short','IND RO short','IND EN short','% of GDP (2018)','GDP gain/loss in 2020 Q2 (%)']]\n",
    "df.columns=['HU','RO','EN','share','q2']\n",
    "df['share']=df['share'].str.replace('%','').astype(float)\n",
    "df['q2']=df['q2'].str.replace('%','').astype(float)\n",
    "df['value']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for lang in languages:\n",
    "    dc=df[[lang,'share','q2','value']]\n",
    "    dc.columns=['id','x','y','value']\n",
    "    dc['c']=(dc['x']/dc['x'].median())*dc['y']\n",
    "    open(htmlipath+'panels/matrix_'+lang+'.json','w').write(json.dumps(list(dc.T.to_dict().values())))\n",
    "    # open('matrix_'+lang+'.json','w').write(json.dumps(list(dc.T.to_dict().values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds=szotardf[languages].loc[['% of GDP (2018)','GDP gain/loss in 2020 Q2 (%)']].T\n",
    "ds.columns=['x','y']\n",
    "open(htmlipath+'panels/matrix_label.json','w').write(json.dumps(ds.to_dict()))\n",
    "#open('matrix_label.json','w').write(json.dumps(ds.to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
